{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "fileRoot = \"D:\\\\ICLR-CropDisease\\\\dataset\\\\\"\n",
    "zipsize =256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur(image):\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], np.float32)\n",
    "    return cv2.filter2D(image, -1, kernel=kernel)\n",
    "def preprocess(res):\n",
    "    #zipsize = 256\n",
    "    res = cv2.resize(res, dsize=(zipsize, zipsize))\n",
    "    res = blur(res)\n",
    "    #res = res [64:192,64:192]\n",
    "    return res\n",
    "\n",
    "def loadData():\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "    data_img = []\n",
    "    data_label = []\n",
    "    for file in os.listdir(fileRoot + \"train\\\\healthy_wheat\\\\\"):\n",
    "        img = cv2.imread(fileRoot + \"train\\\\healthy_wheat\\\\\" + file)\n",
    "        res = preprocess(img)\n",
    "        data_img.append(res)\n",
    "        data_label.append(0)\n",
    "        data_img.append(cv2.flip(res, 1))\n",
    "        data_label.append(0)\n",
    "        data_img.append(cv2.flip(res, 0))\n",
    "        data_label.append(0)\n",
    "        data_img.append(cv2.flip(res, -1))\n",
    "        data_label.append(0)\n",
    "        data_img.append(datagen.random_transform(res))\n",
    "        data_label.append(0)\n",
    "        data_img.append(datagen.random_transform(res))\n",
    "        data_label.append(0)\n",
    "\n",
    "    for file in os.listdir(fileRoot + \"train\\\\leaf_rust\\\\\"):\n",
    "        img = cv2.imread(fileRoot + \"train\\\\leaf_rust\\\\\" + file)\n",
    "        if img is None:\n",
    "            print(file)\n",
    "            continue\n",
    "        res = preprocess(img)\n",
    "        data_label.append(1)\n",
    "        data_img.append(res)\n",
    "        data_img.append(cv2.flip(res, 1))\n",
    "        data_label.append(1)\n",
    "        data_img.append(cv2.flip(res, 0))\n",
    "        data_label.append(1)\n",
    "        data_img.append(cv2.flip(res, -1))\n",
    "        data_label.append(1)\n",
    "        data_img.append(datagen.random_transform(res))\n",
    "        data_label.append(1)\n",
    "        data_img.append(datagen.random_transform(res))\n",
    "        data_label.append(1)\n",
    "\n",
    "    for file in os.listdir(fileRoot + \"train\\\\stem_rust\\\\\"):\n",
    "        img = cv2.imread(fileRoot + \"train\\\\stem_rust\\\\\" + file)\n",
    "        res = preprocess(img)\n",
    "        data_img.append(res)\n",
    "        data_label.append(2)\n",
    "        data_img.append(cv2.flip(res, 1))\n",
    "        data_label.append(2)\n",
    "        data_img.append(cv2.flip(res, 0))\n",
    "        data_label.append(2)\n",
    "        data_img.append(cv2.flip(res, -1))\n",
    "        data_label.append(2)\n",
    "        data_img.append(datagen.random_transform(res))\n",
    "        data_label.append(2)\n",
    "        data_img.append(datagen.random_transform(res))\n",
    "        data_label.append(2)\n",
    "        \n",
    "    for i in range(len(data_img)):\n",
    "        data_img[i] = data_img[i] / 255\n",
    "    data_img = np.array(data_img)\n",
    "    data_label = np.array(data_label)\n",
    "    return data_img, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestSplit(data_img,data_label):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_img,data_label,test_size = 0.3)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transferModel(X_train, X_test, y_train, y_test):\n",
    "    with tf.device('/gpu:0'):\n",
    "        \n",
    "        base_model = tf.keras.applications.VGG19(input_shape=(zipsize, zipsize, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "        for layer in base_model.layers[:20]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        dense_layer = tf.keras.layers.Dense(128)\n",
    "        drop_layer = tf.keras.layers.Dropout(0.3)\n",
    "        prediction_layer = tf.keras.layers.Dense(3)\n",
    "\n",
    "\n",
    "        model = tf.keras.Sequential([base_model,global_average_layer,dense_layer,drop_layer,prediction_layer])\n",
    "        print(model.summary())\n",
    "        model.compile(optimizer='Adamax',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "        # Train\n",
    "        history = model.fit(X_train, y_train,batch_size = 16, epochs=50,use_multiprocessing = True)\n",
    "\n",
    "        # test\n",
    "        test_loss, test_acc = model.evaluate(X_test,y_test, batch_size = 16, verbose=2)\n",
    "        print(test_acc)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(X_train, X_test, y_train, y_test):\n",
    "   \n",
    "    with tf.device('/gpu:0'):\n",
    "        \n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(zipsize, zipsize, 3)))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(128, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(3,activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer='Adamax',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # Train\n",
    "        history = model.fit(X_train, y_train,batch_size = 16, epochs=50,use_multiprocessing = True)\n",
    "\n",
    "        # test\n",
    "        test_loss, test_acc = model.evaluate(X_test,y_test, batch_size = 16, verbose=2)\n",
    "        print(test_acc)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7U06EV.gif\n",
      "DATA READY\n"
     ]
    }
   ],
   "source": [
    "data_img,data_lable = loadData()\n",
    "print(\"DATA READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "61693952/80134624 [======================>.......] - ETA: 1s"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = trainTestSplit(data_img,data_lable)\n",
    "\n",
    "model = transferModel(X_train, X_test, y_train, y_test)\n",
    "#data_label = np.array(data_lable)\n",
    "#model = trainModel(data_img,[],data_label,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTest():\n",
    "    test = []\n",
    "    name = []\n",
    "    for file in os.listdir(fileRoot + \"test\\\\\"):\n",
    "        img = cv2.imread(fileRoot + \"test\\\\\" + file)\n",
    "        res = preprocess(img)\n",
    "        test.append(res)\n",
    "        name.append(file)\n",
    "    for i in range(len(test)):\n",
    "        test[i] = test[i] / 255\n",
    "    test = np.array(test)\n",
    "    result = model.predict_proba(test)\n",
    "    return name, result\n",
    "name,result = loadTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "output = []\n",
    "for i in range(len(result)):\n",
    "    output.append(np.append(result[i],name[i][0:6]).tolist())\n",
    "my_df = pd.DataFrame(output)\n",
    "my_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
