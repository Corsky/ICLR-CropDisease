{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Zhilin Guo (zg2358) & Fangpu He (fh2398)  \n4701 AI Kaggle Competition**\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ndir_path = '/kaggle/input/f2019-aihw7/'\nfor dirname, _, filenames in os.walk(dir_path):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# These paths are unique to Kaggle, obviously. Use your local path or colab path, depending on which you're using.\ntrain_x = np.load(dir_path+'mnist-train-images.npy')\ntrain_y = np.load(dir_path+'mnist-train-labels.npy')\nval_x = np.load(dir_path+'mnist-val-images.npy')\nval_y = np.load(dir_path+'mnist-val-labels.npy')\n\nscan_train_x = np.load(dir_path+'scan-train-images.npy')\nscan_train_y = np.load(dir_path+'scan-train-labels.npy')\nscan_test_x = np.load(dir_path+'scan-test-images.npy')\n\n# Verify that their shapes are what we expect\nprint(\"train_x shape:\", train_x.shape)\nprint(\"train_y shape:\", train_y.shape)\nprint(\"val_x shape:\", val_x.shape)\nprint(\"val_y shape:\", val_y.shape)\nprint()\nprint(\"scan_train_x shape:\", scan_train_x.shape)\nprint(\"scan_train_y shape:\", scan_train_y.shape)\nprint(\"scan_test_x shape:\", scan_test_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\n\n# show each image, and make each title the label\n# these are grayscale images so use appropriate heatmap\nax1.imshow(train_x[4701], cmap=plt.get_cmap('gray'))\nax1.set_title(str(train_y[4701]))\nax2.imshow(train_x[4702], cmap=plt.get_cmap('gray'))\nax2.set_title(str(train_y[4702]))\nax3.imshow(train_x[4703], cmap=plt.get_cmap('gray'))\nax3.set_title(str(train_y[4703]))\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print data type\nprint(\"Data type:\", train_x.dtype)\n# just to make sure, print the min/max too\nprint(\"Data min:\", np.amin(train_x[4701]))\nprint(\"Data max:\", np.amax(train_x[4701]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Data type:\", train_y.dtype)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nax.hist(train_y, bins=range(11))\nax.set_xticks(range(10))\nax.set_title(\"MNIST Training Set Class Distribution\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.datasets import mnist\n\n#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\nx_train = np.concatenate((train_x, scan_train_x))\ny_train = np.concatenate((train_y, scan_train_y))\n\nx_test = val_x\ny_test = val_y\n\n# This is a quirk of keras; since the images are grayscale,\n# we need to add an axis so the shape is (60000, 28, 28, 1)\n# instead of (60000, 28, 28)\n\nx_train = x_train[:,:,:,np.newaxis]\nx_test = x_test[:,:,:,np.newaxis]\n\n# We're also going to convert 0~255 to 0~1 float.\nx_train = x_train.astype(np.float)\nx_test = x_test.astype(np.float)\n\nx_train /= 255\nx_test /= 255\n\n# Finally, the classes need to be one-hot encoded.\n# That is:\n# 0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n# 1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n# etc.\n# This is to match what the network will output - \n# there are 10 nodes at the end, each with its own\n# confidence of its class. The ground truth should be\n# 100% confidence of the true label.\n\ny_train = keras.utils.to_categorical(y_train, 10)\ny_test = keras.utils.to_categorical(y_test, 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation\n#                        Remember these?\n\n# By the way, we really like powers of 2 for the number\n# of nodes at each layer.\n\n# model = Sequential([\n#     # input layer, 16 conv (spatial) perceptrons of size (3,3)\n#     # image shape is (28, 28, 1). If it was color it'd be (28, 28, 3)\n#     Conv2D(30, (5,5), activation='relu', input_shape=(28, 28, 1)),\n#     # Now for the max pooling to make the size smaller\n#     MaxPooling2D(pool_size=(2,2)),\n#     # Flatten before sending to Dense (2D to 1D)\n#     Flatten(),\n#     # Output layer with 10 nodes for 10 classes, with softmax\n#     Dense(10, activation='softmax')\n# ])\n\n#our own model with sequential layers\nmodel = Sequential([\n    # input layer, 16 conv (spatial) perceptrons of size (3,3)\n    # image shape is (28, 28, 1). If it was color it'd be (28, 28, 3)\n    Conv2D(64, kernel_size=(6,6), activation='relu', input_shape=(28, 28, 1)),\n    # Now for the max pooling to make the size smaller\n    MaxPooling2D(),\n    \n    # another Conv2D layer\n    Conv2D(32, (5,5), activation='relu'),\n    MaxPooling2D(),\n    \n    \n    # prevent overfitting\n    Dropout(0.1),\n    \n    # Flatten before sending to Dense\n    Flatten(),\n    \n    # multiple dense layers\n    Dense(256, activation='relu'),\n    Dense(256, activation='relu'),\n    Dense(256, activation='relu'),\n    Dense(128, activation='relu'),\n    Dense(64, activation='relu'),\n    Dense(32, activation='relu'),\n    \n    # Output layer with 10 nodes for 10 classes, with softmax\n    Dense(10, activation='softmax')\n])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=keras.losses.categorical_crossentropy,\n             optimizer=keras.optimizers.SGD(),\n             metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nstart = time.time()\nmodel.fit(x_train,        # training data\n          y_train,        # training labels\n          batch_size=300,  # how many training examples you want to give at once\n          verbose=1,      # print progress in console\n          validation_data=(x_test, y_test),  # validation data to check generalization\n          epochs= 1000)       # how many times to go through the entire training set\nend = time.time()\nprint(\"Training took\", end-start, \"seconds.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import csv\n\nscan_test_x = np.load(dir_path+'scan-test-images.npy')\nscan_test_x = scan_test_x[:,:,:,np.newaxis]\nscan_test_x = scan_test_x.astype(np.float)\nscan_test_x /= 255\n\nwith open('output.csv', mode='w') as csv_file:\n    res = model.predict(scan_test_x)\n    csv_writer = csv.writer(csv_file)\n    csv_writer.writerow([\"Id\", \"Category\"])\n    id = 0\n    for pred_res in res:\n        pred_num = np.argmax(pred_res)\n        csv_writer.writerow([id, pred_num])\n        id += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scan_test_x = np.load(dir_path+'scan-test-images.npy')\n\nfig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\n\n# show each image, and make each title the label\n# these are grayscale images so use appropriate heatmap\nax1.imshow(scan_test_x[0], cmap=plt.get_cmap('gray'))\nax2.imshow(scan_test_x[1], cmap=plt.get_cmap('gray'))\nax3.imshow(scan_test_x[2], cmap=plt.get_cmap('gray'))\n\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}